{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for pre processing\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# scikit learn libraries for machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import warnings\n",
    "\n",
    "# pytorch libraries for deep learning models\n",
    "import torch\n",
    "from torchvision import models,transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as graph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_eval_data(base_dataset_path,t_normal_images_path,t_affected_images_path,e_normal_images_path,e_affected_images_path,flag):\n",
    "\tt_normal_images=glob(base_dataset_path+t_normal_images_path+'\\*.jpg')\n",
    "\tt_affected_images=glob(base_dataset_path+t_affected_images_path+'\\*.jpg')\n",
    "\te_normal_images=glob(base_dataset_path+e_normal_images_path+'\\*.jpg')\n",
    "\te_affected_images=glob(base_dataset_path+e_affected_images_path+'\\*.jpg')\n",
    "\t#print(\"Normal images for training:%d\"%(len(t_normal_images)))\n",
    "\t#print(\"Affected images for training:%d\"%(len(t_affected_images)))\n",
    "\ttrain_features=[]\n",
    "\ttrain_labels=[]\n",
    "\teval_features=[]\n",
    "\teval_labels=[]\n",
    "\n",
    "\tt_e_normal_affected_images=[t_normal_images,t_affected_images,e_normal_images,e_affected_images]\n",
    "\t\n",
    "\tfor images in t_e_normal_affected_images:\n",
    "\t\tindex=t_e_normal_affected_images.index(images)\n",
    "\t\tfor image in images:\n",
    "\t\t\timg=cv2.imread(image,0)\n",
    "\t\t\t#img=cv2.resize(img,(28,28))\n",
    "\t\t\timg_2d=np.array(img)\n",
    "\t\t\tif flag==1:\n",
    "\t\t\t\timg_2d=img_2d.reshape(1,40,40)\n",
    "\t\t\telse:\n",
    "\t\t\t\timg_2d=img_2d.ravel()\n",
    "\n",
    "\t\t\tif index == 0 or index == 1:\n",
    "\t\t\t\ttrain_features.append(img_2d)\n",
    "\t\t\t\tif index%2 == 0:\n",
    "\t\t\t\t\ttrain_labels.append(0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttrain_labels.append(1)\n",
    "\t\t\telse:\n",
    "\t\t\t\teval_features.append(img_2d)\n",
    "\t\t\t\tif index%2 == 0:\n",
    "\t\t\t\t\teval_labels.append(0)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\teval_labels.append(1)\n",
    "\n",
    "\n",
    "\treturn np.array(train_features),np.array(train_labels),np.array(eval_features),np.array(eval_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for executing logistic regression\n",
    "def logistic_regression(train_features,train_labels,eval_features,eval_labels):\n",
    "    print(\"Logistic Regression:\")\n",
    "    print(\"Training started...\")\n",
    "    log_reg_classifier=LogisticRegression(solver='saga',verbose=0,tol=1e-3,max_iter=1000)\n",
    "    log_reg_classifier.fit(train_features,train_labels)\n",
    "    print(\"Training finished...\")\n",
    "    print(\"Accuracy on training dataset is %f\"%(log_reg_classifier.score(train_features,train_labels)))\n",
    "    print(\"Accuracy on evaluation dataset is %f\"%(log_reg_classifier.score(eval_features,eval_labels)))\n",
    "    \n",
    "\n",
    "#Function for executing support_vector_machine\n",
    "def support_vector_machine(train_features,train_labels,eval_features,eval_labels):\n",
    "    print(\"Support Vector Machine:\")\n",
    "    print(\"Training started...\")\n",
    "    svm_classifier=svm.LinearSVC(C=100,verbose=0,tol=1e-3)\n",
    "    svm_classifier.fit(train_features,train_labels)\n",
    "    print(\"Training finished...\")\n",
    "    print(\"Accuracy on training dataset is %f\"%(svm_classifier.score(train_features,train_labels)))\n",
    "    print(\"Accuracy on evaluation dataset is %f\"%(svm_classifier.score(eval_features,eval_labels)))\n",
    "    \n",
    "\n",
    "#Function for executing LR + SVM \n",
    "def ensemble_logreg_svm(train_features,train_labels,eval_features,eval_labels):\n",
    "    print(\"Logistic Regression + Support Vector Machine:\")\n",
    "    print(\"Training started...\")\n",
    "    log_reg_classifier=LogisticRegression()\n",
    "    svm_classifier=svm.LinearSVC()\n",
    "    en_lr_svm = VotingClassifier(estimators=[('lr',log_reg_classifier),('svm',svm_classifier)],voting='hard')\n",
    "    en_lr_svm.fit(train_features,train_labels)\n",
    "    print(\"Training finished...\")\n",
    "    print(\"Accuracy on training dataset is %f\"%(en_lr_svm.score(train_features,train_labels)))\n",
    "    print(\"Accuracy on evaluation dataset is %f\"%(en_lr_svm.score(eval_features,eval_labels)))\n",
    "\n",
    "#Function for executing resnet\n",
    "def resnet(flag,skip):\n",
    "    # Create model\n",
    "    if(flag==152):\n",
    "        resnet = models.resnet152(pretrained=True)\n",
    "        print(\"Resnet152\")\n",
    "    elif(flag==50):\n",
    "        print(\"Resnet50\")\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "    \n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    resnet.fc = torch.nn.Linear(resnet.fc.in_features,2)\n",
    "    \n",
    "    # Prepare data\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_data = ImageFolder(root=r'data\\train',transform=transform)\n",
    "    eval_data = ImageFolder(root=r'data\\test',transform=transform)\n",
    "\n",
    "    # define few hyper parameter\n",
    "\n",
    "    batch_size = 1\n",
    "\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    optimizer = torch.optim.SGD(resnet.fc.parameters(),lr=learning_rate,momentum=0.9)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # create dataloader\n",
    "    train_data_loader=data_utils.DataLoader(dataset=train_data,shuffle=True,batch_size=batch_size)\n",
    "    eval_data_loader=data_utils.DataLoader(dataset=eval_data,shuffle=True,batch_size=batch_size)\n",
    "\n",
    "    # Important performance measure variables\n",
    "    best_accuracy = 0.0\n",
    "    best_loss = 1000000\n",
    "    epoch = 0\n",
    "    epoch_list=[]\n",
    "    train_loss_list=[]\n",
    "    train_acc_list=[]\n",
    "    eval_loss_list=[]\n",
    "    eval_acc_list=[]\n",
    "    if(skip==False):\n",
    "        print(\"Training started...\")\n",
    "        while (best_accuracy !=1.000):\n",
    "            #print(\"Epoch:%d\"%(epoch+1))\n",
    "            total_loss = 0\n",
    "            total_trained = 0\n",
    "            total_correct = 0\n",
    "            for i,(train_features,train_labels) in enumerate(train_data_loader):\n",
    "\n",
    "                train_features=Variable(train_features)\n",
    "                train_labels=Variable(train_labels)\n",
    "\n",
    "                resnet.train()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = resnet(train_features)\n",
    "\n",
    "                _ , predicted = torch.max(output.data,1)\n",
    "\n",
    "                loss = criterion(output,train_labels)\n",
    "\n",
    "                total_loss += loss.data\n",
    "                total_trained += len(train_labels)\n",
    "\n",
    "                total_correct += (predicted==train_labels.data)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "            train_current_accuracy = float(total_correct)/total_trained\n",
    "            #print(\"Epoch:%d\"%(epoch+1))\n",
    "            #print(\"Training loss:%f Training accuracy:%f\"%(total_loss,train_current_accuracy))\n",
    "            # temporary changes\n",
    "            epoch_list.append(epoch+1)\n",
    "            train_loss_list.append(total_loss)\n",
    "            train_acc_list.append(train_current_accuracy)\n",
    "\n",
    "            total_loss = 0\n",
    "            total_eval = 0\n",
    "            total_correct = 0\n",
    "            for i,(eval_features,eval_labels) in enumerate(eval_data_loader):\n",
    "\n",
    "                eval_features=Variable(eval_features)\n",
    "                eval_labels=Variable(eval_labels)\n",
    "\n",
    "                resnet.eval()\n",
    "\n",
    "                output = resnet(eval_features)\n",
    "\n",
    "                _ , predicted = torch.max(output.data,1)\n",
    "\n",
    "                loss = criterion(output,train_labels)\n",
    "\n",
    "                total_loss += loss.data\n",
    "                total_eval += len(train_labels)\n",
    "\n",
    "                total_correct += (predicted==eval_labels.data)\n",
    "\n",
    "\n",
    "            eval_current_accuracy = float(total_correct)/total_eval\n",
    "            #print(\"Eval loss:%f Eval accuracy:%f\"%(total_loss,eval_current_accuracy))        \n",
    "            eval_loss_list.append(total_loss)\n",
    "            eval_acc_list.append(eval_current_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #print(\"Loss :%f Total trained :%d Total correct :%d Accuracy:%f\"%(total_loss,total_trained,total_correct,current_accuracy))\n",
    "\n",
    "            if train_current_accuracy > best_accuracy :\n",
    "                best_model = resnet.state_dict()\n",
    "                best_accuracy = train_current_accuracy\n",
    "                #print(\"This is the best state so far\")\n",
    "\n",
    "            epoch +=1\n",
    "\n",
    "        print(\"Training finished...\")\n",
    "        print(\"Accuracy on training dataset is %f\",best_accuracy)\n",
    "        \n",
    "        #Load model with the parameters\n",
    "        model=resnet\n",
    "        model.load_state_dict(best_model)\n",
    "        \n",
    "        if(flag==152):\n",
    "            torch.save(best_model,'./resnet152.pth')\n",
    "        else:\n",
    "            torch.save(best_model,'./resnet50.pth')\n",
    "    else:\n",
    "        model = resnet\n",
    "        if(flag==152):\n",
    "            model.load_state_dict(torch.load('./resnet152.pth'))\n",
    "        else:\n",
    "            model.load_state_dict(torch.load('./resnet50.pth'))\n",
    "            \n",
    "    model.eval()\n",
    "    total_eval = 0\n",
    "    correct_eval = 0\n",
    "    for i,(eval_features,eval_labels) in enumerate(eval_data_loader):\n",
    "        eval_features=Variable(eval_features)\n",
    "        \n",
    "        eval_labels=Variable(eval_labels)\n",
    "        \n",
    "        output=model(eval_features)\n",
    "        \n",
    "        _,predicted = torch.max(output.data,1)\n",
    "        \n",
    "        total_eval += len(eval_labels)\n",
    "        \n",
    "        correct_eval += (predicted==eval_labels.data).sum()\n",
    "\n",
    "    print(\"The accuracy on evaluation dataset is %f\"%(float(correct_eval)/total_eval))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Specify the dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset_path=r'..\\Data_Set\\resized_Images'\n",
    "train_normal_images_path=r'\\train_normal'\n",
    "train_affected_images_path=r'\\train_affected'\n",
    "eval_normal_images_path=r'\\test_normal'\n",
    "eval_affected_images_path=r'\\test_affected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images for training :54\n",
      "Total Images for evaluation :18\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Training started...\n",
      "Training finished...\n",
      "Accuracy on training dataset is 1.000000\n",
      "Accuracy on evaluation dataset is 1.000000\n",
      "\n",
      "\n",
      "Support Vector Machine:\n",
      "Training started...\n",
      "Training finished...\n",
      "Accuracy on training dataset is 1.000000\n",
      "Accuracy on evaluation dataset is 1.000000\n",
      "\n",
      "\n",
      "Logistic Regression + Support Vector Machine:\n",
      "Training started...\n",
      "Training finished...\n",
      "Accuracy on training dataset is 1.000000\n",
      "Accuracy on evaluation dataset is 1.000000\n",
      "\n",
      "\n",
      "Resnet50\n",
      "The accuracy on evaluation dataset is 1.000000\n",
      "\n",
      "\n",
      "Resnet152\n",
      "The accuracy on evaluation dataset is 0.666667\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "train_features,train_labels,eval_features,eval_labels=get_train_eval_data(base_dataset_path,train_normal_images_path,train_affected_images_path,eval_normal_images_path,eval_affected_images_path,0)\n",
    "print(\"Total Images for training :%d\"%(len(train_features)))\n",
    "print(\"Total Images for evaluation :%d\"%(len(eval_labels)))\n",
    "print(\"\\n\")\n",
    "logistic_regression(train_features,train_labels,eval_features,eval_labels)\n",
    "print(\"\\n\")\n",
    "support_vector_machine(train_features,train_labels,eval_features,eval_labels)\n",
    "print(\"\\n\")\n",
    "ensemble_logreg_svm(train_features,train_labels,eval_features,eval_labels)\n",
    "print(\"\\n\")\n",
    "resnet(50,skip=True) #if training required then set skip = False , else True\n",
    "print(\"\\n\")\n",
    "resnet(152,skip=True) #if training required then set skip = False , else True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
